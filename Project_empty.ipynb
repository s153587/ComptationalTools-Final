{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for loading data, statistics and clustering,\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used directly in jupyter but used in the script files\n",
    "# created and tested by jupyter. Used in mapreduce scripts.\n",
    "import mrjob\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to make sql queries and print them nicely.\n",
    "import sqlite3\n",
    "from textwrap import indent,dedent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for directory in [\"./Scripts\", \"./Sqlite\"]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_read = \"Data/Wikipedia_Editor_Survey_2012_-_anonymized_dataset.csv\"\n",
    "filepath_save = \"Data/Wikipedia_Editor_Survey_2012_-_anonymized_dataset_clean.csv\"\n",
    "time,age = columns = [\"Q20_1_TEXT\", \"Q21\"]\n",
    "\n",
    "df = pd.read_csv(filepath_read, low_memory=False)\n",
    "\n",
    "df = df[[age,time]] # Extract columns\n",
    "\n",
    "df.loc[df[age] == \"Decline to state\", age] = np.nan # turn \"decline\" into nan\n",
    "df.loc[df[age] == \"_ 18\", age] = 0                  # less than 18 => 0\n",
    "df.loc[df[age] == \"> 99\", age] = 100                # More than 99 => 100\n",
    "\n",
    "df.dropna(inplace=True)    # Drop NaN / None / Null\n",
    "df.drop([0], inplace=True) # Remove first row with string questions\n",
    "df = df.astype(int)        # Convert all to int\n",
    "\n",
    "df.to_csv(filepath_save, index=False, header=False)\n",
    "\n",
    "# Display sample of data saved\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.rename(columns={'Q20_1_TEXT':'Time','Q21':'Age',}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Load Clean Data Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"Data/Wikipedia_Editor_Survey_2012_-_anonymized_dataset_clean.csv\"\n",
    "names = [\"Age\",\"Time\"]\n",
    "\n",
    "df = pd.read_csv(filepath, names=names, dtype=dict((n,int) for n in names))\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Load Clean Data Open(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath) as f:\n",
    "    for i,line in enumerate(f):\n",
    "        line = line.rstrip()\n",
    "        answers = line.split(',')\n",
    "        print(f'line {i}: Age:{answers[0]:>3}, Time:{answers[1]:>3}, Raw text: \"{line}\\\\n\"')\n",
    "        if i == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serves to provide a simple overview of the data-set rather than be an actual part of the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_points(column = 0, filepath = 'Data/Wikipedia_Editor_Survey_2012_-_anonymized_dataset_clean.csv'):\n",
    "    \n",
    "    # Load points using the example provided earlier\n",
    "    with open(filepath) as f:\n",
    "        for i,line in enumerate(f):\n",
    "            cols = line.rstrip().split(',')\n",
    "            yield int(cols[column])\n",
    "            \n",
    "age_points  = list(load_points(0))\n",
    "time_points = list(load_points(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(points, title):\n",
    "    print(f'Summary staticstics for {title}')\n",
    "    print('Mean: %0.2f +- %0.2f' % (np.mean(points), np.std(points)))\n",
    "    print('Min: %d, Max: %d\\n' % (np.min(points), np.max(points)))\n",
    "\n",
    "summary(age_points, 'Age')\n",
    "summary(time_points, 'Time')\n",
    "print(f'Completed summary statistics for {len(age_points)} respondents!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un-parallelized implementation of K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "MAX_AGE  = 100\n",
    "MAX_TIME = 96\n",
    "\n",
    "CLUSTER_COUNT = 6\n",
    "MAX_ITERATIONS = 100\n",
    "PRECISION = 2\n",
    "\n",
    "def nearest_centroid(point, centroids):\n",
    "    dists = np.array([abs(centroid - point) for centroid in centroids])\n",
    "    return np.argmin(dists)\n",
    "\n",
    "def k_means(points, k = CLUSTER_COUNT, max_iterations = MAX_ITERATIONS, precision = PRECISION):\n",
    "    \n",
    "    # Optionally change precision for output\n",
    "    np.set_printoptions(precision=precision)\n",
    "    \n",
    "    # Initialize centroids uniformly\n",
    "    centroids = np.array([idx*MAX_AGE/(k+0.5) for idx in range(k)])\n",
    "    \n",
    "    def update_centroids():\n",
    "        return np.array([np.mean(cluster) for cluster in clusters])\n",
    "    \n",
    "    def is_converged():\n",
    "        for i, centroid in enumerate(centroids):\n",
    "            if centroid != updated_centroids[i]:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        \n",
    "        # Initialize clean clusters\n",
    "        clusters = [[] for idx in range(k)]\n",
    "        \n",
    "        # Assign points to nearest cluster and update\n",
    "        for point in points:\n",
    "            clusters[nearest_centroid(point, centroids)].append(point)\n",
    "        updated_centroids = update_centroids()\n",
    "\n",
    "        if is_converged():\n",
    "            print(f'Converged after {iteration+1} iterations with the following centroids:\\n{updated_centroids}\\n')\n",
    "            return updated_centroids\n",
    "    \n",
    "        centroids = updated_centroids\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "# Compute centroids from previously loaded points\n",
    "age_centroids  = k_means(age_points)\n",
    "time_centroids = k_means(time_points)\n",
    "\n",
    "def get_upper_bounds(centroids, xmin, xmax):\n",
    "    upper_bound = []\n",
    "    prev_centroid = None\n",
    "    for i in range(xmin, xmax):\n",
    "        centroid = nearest_centroid(i, centroids)\n",
    "        if centroid != prev_centroid and centroid > 0:\n",
    "            upper_bound.append(i)\n",
    "        prev_centroid = centroid\n",
    "    return upper_bound\n",
    "\n",
    "# Get upper-bound representation of centroids for each column\n",
    "print('Upper bounds for age: ', get_upper_bounds(age_centroids, 0, MAX_AGE))\n",
    "print('Upper bounds for time:', get_upper_bounds(time_centroids, 0, MAX_TIME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, the (integer) upper bound for each cluster in a column (age, time) has been found. Note that points beyond the last bound are implicitly assigned to the remaining cluster, as that check is unneccessary. These bounds will be used for the remainder of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReduce Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file Scripts/_bins.py\n",
    "# This file serves as common binning functions for all MapReduce classes\n",
    "\n",
    "# Bounds found from clusters\n",
    "_agebounds = [12, 27, 38, 51, 64] # + [ >= 64 ]\n",
    "_timebounds = [8, 21, 37, 52, 68] # + [ >= 68 ]\n",
    "\n",
    "# Bound which are better for PCC\n",
    "_timebounds = [1, 3, 6, 10, 16] # + [ >= 16 ]\n",
    "\n",
    "def agebin(age):\n",
    "    age = int(age)\n",
    "    for i,val in enumerate(_agebounds):\n",
    "        if age < val:\n",
    "            return i\n",
    "    return len(_agebounds)\n",
    "        \n",
    "def timebin(time):\n",
    "    time = int(time)\n",
    "    for i,val in enumerate(_timebounds):\n",
    "        if time < val:\n",
    "            return i\n",
    "    return len(_timebounds)\n",
    "\n",
    "def getUpperBounds():\n",
    "    return _agebounds, _timebounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test import from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts._bins import agebin,timebin,getUpperBounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Age Groups MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file Scripts/agegroups.py\n",
    "from mrjob.job import MRJob\n",
    "from _bins import agebin\n",
    "\n",
    "class MRJobAgeGroups(MRJob):\n",
    "    \n",
    "    # Map: keyval = (age,1)\n",
    "    def mapper(self, _, line):\n",
    "        answers = line.split(\",\")\n",
    "        yield agebin(answers[0]), 1\n",
    "    \n",
    "    # Red: keyval = (age,sum([1,1..1]))\n",
    "    def reducer(self, agegroup, counts):\n",
    "        yield agegroup, sum(counts)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRJobAgeGroups.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Distinct Grouped Answers MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file Scripts/distinct.py\n",
    "from mrjob.job import MRJob\n",
    "from _bins import agebin,timebin\n",
    "\n",
    "class MRJobDistinct(MRJob):\n",
    "    \n",
    "    # Map: keyval = ((age,time),1)\n",
    "    def mapper(self, _, line):\n",
    "        answers = line.split(\",\")\n",
    "        yield (agebin(answers[0]), timebin(answers[1])), 1\n",
    "    \n",
    "    # Red: keyval = ((age,time),sum([1,1..1]))\n",
    "    def reducer(self, group, counts):\n",
    "        yield group, sum(counts)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRJobDistinct.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Age Time Correlation MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file Scripts/corr.py\n",
    "import mrjob\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from _bins import agebin,timebin\n",
    "\n",
    "class MRJobPearsonCorr(MRJob):\n",
    "    \n",
    "    # Remove key from output\n",
    "    OUTPUT_PROTOCOL = mrjob.protocol.JSONValueProtocol\n",
    "    \n",
    "    # Mapper mapping each partial sum of each sum-variable for each line in file\n",
    "    # Map: keyval = (\"var_i\",var_i_j), var_i = {\"n\",\"x\",\"xx\",\"xy\",\"y\",\"y\"}\n",
    "    def mapper(self, _, line):\n",
    "        answers = line.split(\",\")\n",
    "        xi,yi = agebin(answers[0]), timebin(answers[1])\n",
    "        yield \"n\",  1,\n",
    "        yield \"x\",  xi\n",
    "        yield \"xx\", xi*xi\n",
    "        yield \"xy\", xi*yi\n",
    "        yield \"y\",  yi\n",
    "        yield \"yy\", yi*yi\n",
    "    \n",
    "    # Reducer summarising each variable\n",
    "    # Map: keyval = (\"var_i\",sum(var_i_j)),\n",
    "    #               var_i = {\"n\",\"x\",\"xx\",\"xy\",\"y\",\"y\"}, j = 0..n-1\n",
    "    def reducer_sum(self, var, values):\n",
    "        yield None, (var, sum(values))\n",
    "     \n",
    "    # Reducer extracting variables and computing PCC\n",
    "    # Map: value = PCC(n,x,xx,xy,y,yy)\n",
    "    def reducer_pearson(self, _, varsumpairs):\n",
    "        # Sort by var name and extract into variables (6 vars)\n",
    "        n,x,xx,xy,y,yy = (varsum for _,varsum in sorted(varsumpairs))\n",
    "        yield None, ( xy-x*y/n ) / ( (xx-(x**2)/n) * (yy-(y**2)/n) )**0.5\n",
    "    \n",
    "    # 2 step to calculate PCC for age and time\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper,\n",
    "                   reducer=self.reducer_sum),\n",
    "            MRStep(reducer=self.reducer_pearson)\n",
    "        ]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRJobPearsonCorr.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Age-group Correlations MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file Scripts/full.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from _bins import agebin,timebin\n",
    "\n",
    "class MRJobDistinct(MRJob):\n",
    "    \n",
    "    # Mapper reading input file into binned (age,time) pairs for counting\n",
    "    # Map: keyval = ((age,time),1)\n",
    "    def mapper_grouped_answers(self, _, line):\n",
    "        answers = line.split(\",\")\n",
    "        yield (agebin(answers[0]), timebin(answers[1])), 1\n",
    "    \n",
    "    # Reducer counting co-occurance of each distinct (age,time) pair\n",
    "    # Red: keyval = (time_k, (age_i, sum([1,1, ... 1])), i = 0..5, k = 0..5 \n",
    "    def reducer_grouped_answers_sum(self, agetime, counts):\n",
    "        age,time = agetime\n",
    "        yield time, (age, sum(counts))\n",
    "    \n",
    "    # Reducer extracting pairs of age pairs and time values\n",
    "    # Red: keyval = ((agei,agej),(time_k_i],[time_k_j])), \n",
    "    #               i = 0..5, j = 1..4 > i, k = 0..5\n",
    "    def reducer_agegroup_pairs(self, time, agetimevalues):\n",
    "        # Sort by age group (scales to amount of agebins)\n",
    "        agetimevalues = sorted(agetimevalues) \n",
    "        for agei,timei in agetimevalues:\n",
    "            for agej,timej in agetimevalues[agei+1:]:\n",
    "                yield (agei,agej),(timei,timej)\n",
    "    \n",
    "    # Mapper mapping all partial-sums for each age-pair\n",
    "    # Map: keyval = ((group-pair,\"var\"), var_i),\n",
    "    #               var = {\"n\",\"x\",\"xx\",\"xy\",\"y\",\"y\"}, i = 0..n-1\n",
    "    def mapper_pearson(self, group, timevalues):\n",
    "        xi,yi = timevalues\n",
    "        yield (group, \"n\"),  1\n",
    "        yield (group, \"x\"),  xi\n",
    "        yield (group, \"xx\"), xi**2\n",
    "        yield (group, \"xy\"), xi*yi\n",
    "        yield (group, \"y\"),  yi\n",
    "        yield (group, \"yy\"), yi**2\n",
    "    \n",
    "    # Reducer summarising each group-pair PCC-variables\n",
    "    # Red: keyval = (group-pair,(\"var\",sum(var_i))),\n",
    "    #               var = {\"n\",\"x\",\"xx\",\"xy\",\"y\",\"y\"}, i = 0..n-1\n",
    "    def reducer_pearson_sum(self, groupvar, partialsums):\n",
    "        group,var = groupvar\n",
    "        yield group, (var, sum(partialsums))\n",
    "    \n",
    "    # Reudcer extracting variables for each group and computing PCC\n",
    "    # Red: keyval = (group-pair, PCC(n,x,xx,xy,y,yy))\n",
    "    def reducer_pearson_compute(self, group, varsumpairs):\n",
    "        # Sort by var name and extract into variables (6 vars)\n",
    "        n,x,xx,xy,y,yy = (varsum for _,varsum in sorted(varsumpairs))\n",
    "        yield group, ( xy-x*y/n ) / ( (xx-(x**2)/n) * (yy-(y**2)/n) )**0.5\n",
    "    \n",
    "    # 4 Steps to complete PCC for all group-pairs\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_grouped_answers,\n",
    "                   reducer=self.reducer_grouped_answers_sum),\n",
    "            MRStep(reducer=self.reducer_agegroup_pairs),\n",
    "            MRStep(mapper=self.mapper_pearson,\n",
    "                   reducer=self.reducer_pearson_sum),\n",
    "            MRStep(reducer=self.reducer_pearson_compute)\n",
    "        ]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRJobDistinct.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python Scripts/agegroups.py Data/Wikipedia_Editor_Survey_2012_-_anonymized_dataset_clean.csv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python Scripts/distinct.py Data/Wikipedia_Editor_Survey_2012_-_anonymized_dataset_clean.csv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python Scripts/corr.py Data/Wikipedia_Editor_Survey_2012_-_anonymized_dataset_clean.csv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python Scripts/full.py Data/Wikipedia_Editor_Survey_2012_-_anonymized_dataset_clean.csv --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sql:\n",
    "    # Static values\n",
    "    table = \"wiki\"\n",
    "    fields = [\"id\", \"age\", \"time\"]\n",
    "    datapath = 'Data/Wikipedia_Editor_Survey_2012_-_anonymized_dataset_clean.csv'\n",
    "    \n",
    "    # Generate table(columns) string (for population)\n",
    "    # optionally with types (for table creation)\n",
    "    def table_cmd(self, crt = False):\n",
    "        fld = ''\n",
    "        for i,field in enumerate(self.fields):\n",
    "            prmkey = ' PRIMARY KEY' if crt and i == 0 else ''\n",
    "            fldtyp = ' INTEGER' + prmkey if crt else ''\n",
    "            fld += field + fldtyp + ', '\n",
    "        return f'{self.table}({fld[:-2]})'\n",
    "\n",
    "    # Shortcut for executing on cursor and committing to db\n",
    "    # optionally without printing the query command.\n",
    "    def exe(self, cmd, verbose = True):\n",
    "        cmd = dedent(cmd)\n",
    "        c = self.db.cursor()\n",
    "        if verbose:\n",
    "            print(cmd)\n",
    "        c.execute(cmd + ';')\n",
    "        self.db.commit()\n",
    "        return c\n",
    "    \n",
    "    # Sets up database, creates and populates table if none is found already,\n",
    "    # optionally by forcing the database to reload from file.\n",
    "    def __init__(self, databaseName, reloadDb = False):\n",
    "        self.db = sqlite3.connect(databaseName)\n",
    "        self.addFuncs()\n",
    "        \n",
    "        tableCheck = self.exe(f'SELECT name FROM sqlite_master WHERE type=\"table\" AND name=\"{self.table}\"', False).fetchone()\n",
    "        if reloadDb and tableCheck:\n",
    "            self.exe(f'DROP TABLE {self.table}')\n",
    "        if reloadDb or not tableCheck:\n",
    "            self.exe(f'CREATE TABLE {self.table_cmd(crt=True)}')\n",
    "            self.populate()\n",
    "    \n",
    "    # Populates table FROM file given in the static path\n",
    "    def populate(self):\n",
    "        with open(self.datapath) as file:\n",
    "            print(\"Populating from file: \"+self.datapath)\n",
    "            for i,line in enumerate(file):\n",
    "                cmd = f'INSERT INTO {self.table_cmd()} VALUES ({i},{line.rstrip()})'\n",
    "                self.exe(cmd, verbose=False)\n",
    "            print(f\"Populating completed, {i} lines loaded.\")\n",
    "    \n",
    "    # Adds non-native support for power and squareroot functions to the database\n",
    "    def addFuncs(self):\n",
    "        def power(a,b):\n",
    "            return float(a)**float(b)\n",
    "        \n",
    "        def sqrt(a):\n",
    "            return float(a)**0.5\n",
    "        \n",
    "        self.db.create_function(\"POW\",2,power)\n",
    "        self.db.create_function(\"SQRT\",1,sqrt)\n",
    "    \n",
    "    # Generates query sub-string for extracting age into bins\n",
    "    # tabs are purely flavour for printing prettily.\n",
    "    def agebin(self, tabs=0):\n",
    "        age = self.fields[1] # \"age\"\n",
    "        agebounds = getUpperBounds()[0]\n",
    "        substring = f\"\"\"\n",
    "            CASE\n",
    "                WHEN {age} < {agebounds[0]} THEN 0\n",
    "                WHEN {age} < {agebounds[1]} THEN 1\n",
    "                WHEN {age} < {agebounds[2]} THEN 2\n",
    "                WHEN {age} < {agebounds[3]} THEN 3\n",
    "                WHEN {age} < {agebounds[4]} THEN 4\n",
    "                ELSE 5\n",
    "            END\"\"\"\n",
    "        return indent(dedent(substring)[1:],\" \"*4*tabs)[4*tabs:]\n",
    "    \n",
    "    # Generates query sub-string for extracting time into bins\n",
    "    # tabs are purely flavour for printing prettily.\n",
    "    def timebin(self, tabs=0):\n",
    "        time = self.fields[2] # \"time\"\n",
    "        timebounds = getUpperBounds()[1]\n",
    "        substring = f\"\"\"\n",
    "            CASE\n",
    "                WHEN {time} < {timebounds[0]} THEN 0\n",
    "                WHEN {time} < {timebounds[1]} THEN 1\n",
    "                WHEN {time} < {timebounds[2]} THEN 2\n",
    "                WHEN {time} < {timebounds[3]} THEN 3\n",
    "                WHEN {time} < {timebounds[4]} THEN 4\n",
    "                ELSE 5\n",
    "            END\"\"\"\n",
    "        return indent(dedent(substring)[1:],\" \"*4*tabs)[4*tabs:]\n",
    "    \n",
    "    # Execute query for counting populations of distinct age groups\n",
    "    def count_age_groups(self):\n",
    "        table = self.table # \"wiki\"\n",
    "        command = f\"\"\"\n",
    "            SELECT\n",
    "                {self.agebin(tabs=4)} AS agebin,\n",
    "                COUNT(*)\n",
    "            FROM\n",
    "                {table}\n",
    "            GROUP BY\n",
    "                agebin\n",
    "        \"\"\"\n",
    "        return self.exe(command).fetchall()\n",
    "    \n",
    "    # Execute query for counting distinct grouped answers\n",
    "    def count_distinct_grouped_answers(self):\n",
    "        table = self.table # \"wiki\"\n",
    "        command = f\"\"\"\n",
    "            SELECT\n",
    "                {self.agebin(tabs=4)} AS agebin,\n",
    "                {self.timebin(tabs=4)} AS timebin,\n",
    "                COUNT(*)\n",
    "            FROM\n",
    "                {table}\n",
    "            GROUP BY\n",
    "                agebin, timebin\n",
    "        \"\"\"\n",
    "        return self.exe(command).fetchall()\n",
    "    \n",
    "    # Execute query for finding pearson correlation\n",
    "    # between the age and the time column\n",
    "    def pearson_age_time_correlation(self):\n",
    "        table = self.table # \"wiki\"\n",
    "        command = f\"\"\"\n",
    "            SELECT\n",
    "                ( xy-x*y/n ) / SQRT( ( xx-POW(x,2)/n ) * ( yy-POW(y,2)/n ) )\n",
    "            FROM (\n",
    "                SELECT\n",
    "                    COUNT(*) AS n,\n",
    "                    SUM(xi) AS x,\n",
    "                    SUM(xi*xi) AS xx,\n",
    "                    SUM(xi*yi) AS xy,\n",
    "                    SUM(yi) AS y,\n",
    "                    SUM(yi*yi) AS yy\n",
    "                FROM (\n",
    "                    SELECT\n",
    "                        {self.agebin(tabs=6)} AS xi,\n",
    "                        {self.timebin(tabs=6)} AS yi\n",
    "                    FROM\n",
    "                        {table}\n",
    "                )\n",
    "            )\n",
    "        \"\"\"\n",
    "        return self.exe(command).fetchone()\n",
    "    \n",
    "    # Execute query for finding pearson correlation\n",
    "    # between time values for age group-pairs.\n",
    "    def pearson_agegroup_correlations(self):\n",
    "        table = self.table # \"wiki\"       \n",
    "        command = f\"\"\"\n",
    "            WITH distinct_grouped_answers AS (\n",
    "                SELECT\n",
    "                    {self.agebin(tabs=5)} AS agebin,\n",
    "                    {self.timebin(tabs=5)} AS timebin,\n",
    "                    COUNT(*) AS i\n",
    "                FROM\n",
    "                    {table}\n",
    "                GROUP BY\n",
    "                    agebin, timebin\n",
    "            )\n",
    "            SELECT\n",
    "                agex,\n",
    "                agey,\n",
    "                ( xy-x*y/n ) / SQRT( ( xx-POW(x,2)/n ) * ( yy-POW(y,2)/n ) )\n",
    "            FROM (\n",
    "                SELECT\n",
    "                    x.agebin AS agex,\n",
    "                    y.agebin AS agey,\n",
    "                    COUNT(*) AS n,\n",
    "                    SUM(x.i) AS x,\n",
    "                    SUM(x.i*x.i) AS xx,\n",
    "                    SUM(x.i*y.i) AS xy,\n",
    "                    SUM(y.i) AS y,\n",
    "                    SUM(y.i*y.i) AS yy\n",
    "                FROM\n",
    "                    distinct_grouped_answers AS x\n",
    "                LEFT JOIN\n",
    "                    distinct_grouped_answers AS y\n",
    "                ON\n",
    "                    x.timebin = y.timebin\n",
    "                WHERE\n",
    "                    x.agebin < y.agebin\n",
    "                GROUP BY\n",
    "                    x.agebin, y.agebin\n",
    "            )\n",
    "        \"\"\"\n",
    "        return self.exe(command).fetchall()\n",
    "    \n",
    "    def close(self):\n",
    "        self.db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = Sql('Sqlite/test.sqlite', reloadDb=True)\n",
    "sql.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = Sql('Sqlite/test.sqlite', reloadDb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql.count_age_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sql.count_distinct_grouped_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sql.pearson_age_time_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql.pearson_agegroup_correlations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
